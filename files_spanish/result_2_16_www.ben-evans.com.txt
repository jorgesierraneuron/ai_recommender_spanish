Buscando casos de uso de IA

Hemos tenido a ChatGPT durante 18 meses, pero ¿para qué sirve? ¿Cuáles son los casos de uso? 
¿Por qué no es útil para todos, ahora mismo? ¿Se convierten los Grandes Modelos de Lenguaje en herramientas universales que pueden realizar cualquier tarea, o los envolvemos en aplicaciones de propósito único y construimos miles de nuevas empresas alrededor de ellas?

Esta imagen proviene de un libro de Martin Honeysett llamado 'Microphobia', publicado en 1982. Está lleno de grandes chistes y podría haber utilizado casi cualquier uno de ellos, porque todos están haciendo el mismo punto - ¿qué se supone que debes hacer con esto? Jugué a Saboteur en el ZX Spectrum que mi padre compró ese año, pero ¿qué más?

Un par de años antes, Dan Bricklin había encontrado una respuesta: vio a un profesor haciendo una hoja de cálculo con tiza en una pizarra, y se dio cuenta de que podías hacer esto en 'software'. Así que creó VisiCalc, la primera hoja de cálculo informática exitosa, y cuando se la mostró a los contables, les voló la mente: podían hacer un trabajo de una semana en una tarde.

Un Apple II para ejecutar VisiCalc costaba al menos $12,000* ajustados por inflación, pero incluso así, la gente sacó sus cheques en cuanto la vieron: las hojas de cálculo informáticas cambiaron el mundo, para los contables.

Benedict EvansSin embargo, si hubieras mostrado VisiCalc a un abogado o un diseñador gráfico, su respuesta podría haber sido 'eso es increíble, y tal vez mi contable debería ver esto, pero no hago eso'. Los abogados necesitaban un procesador de texto, y los diseñadores gráficos necesitaban (digamos) Postscript, Pagemaker y Photoshop, y eso tomó más tiempo.

He estado pensando en este problema mucho en los últimos 18 meses, mientras experimentaba con ChatGPT, Gemini, Claude y todos los demás chatbots que han surgido: 'esto es increíble, pero no tengo ese caso de uso'.

El único caso de uso realmente grande que despegó en 2023 fue escribir código, pero no escribo código. La gente lo utiliza para brainstorming, hacer listas y ordenar ideas, pero de nuevo, no hago eso. No tengo tareas escolares más. Veo a la gente utilizando para obtener un borrador genérico, y a los diseñadores creando bocetos conceptuales con MidJourney, pero, de nuevo, estos no son mis casos de uso. Todavía no he encontrado nada que se ajuste a un caso de uso que tenga. No creo que sea el único, tampoco, como sugiere algunos de los datos de la encuesta - mucha gente ha intentado esto, especialmente desde que no necesitas gastar $12,000 en un nuevo Apple II, y es muy cool, pero ¿cuánto lo usamos, y para qué?

Esto no importaría mucho ('hombre dice que la nueva tecnología no es para él'), excepto que mucha gente en tecnología ve en ChatGPT y LLMs un cambio de paradigma hacia algo que puede ser universal. Una hoja de cálculo no puede hacer procesamiento de texto o diseño gráfico, y una PC puede hacer todas esas cosas, pero alguien necesita escribir esas aplicaciones para ti primero, una a la vez. Pero a medida que estos modelos mejoran y se vuelven multimodales, la tesis transformadora real es que un modelo puede hacer 'cualquier' caso de uso sin que nadie tenga que escribir el software para esa tarea en particular.

Supongamos que quieres analizar las cancelaciones de clientes de este mes, o disputar una multa de estacionamiento, o presentar tus impuestos - puedes preguntarle a un LLM, y trabajará para determinar qué datos necesitas, encontrar los sitios web adecuados, hacerte las preguntas adecuadas, analizar una foto de tu estado de cuenta hipotecaria, llenar los formularios y darte las respuestas. Podríamos mover tareas manuales en órdenes de magnitud más grandes hacia el software, porque no necesitas escribir software para hacer cada una de esas tareas una a una. Esto, creo, es por qué Bill Gates dijo que esto es lo más grande desde la GUI. Eso es mucho más que un asistente de escritura.

Me parece, sin embargo, que hay dos tipos de problemas con esta tesis. El problema estrecho, y tal vez el problema 'débil', es que estos modelos no son lo suficientemente buenos todavía. Se quedarán atascados, bastante a menudo, en los escenarios que sugerí anteriormente. Mientras tanto, estos son sistemas probabilísticos en lugar de deterministas, por lo que son mucho mejores para algunos tipos de tareas que para otros. Ahora son muy buenos para hacer cosas que parecen correctas, y para algunos casos de uso esto es lo que quieres, pero para otros, 'parece correcto' es diferente a 'correcto'. Las tasas de error y las 'alucinaciones' están mejorando todo el tiempo y se están volviendo más manejables, pero no sabemos hacia dónde irá esto - esto es un problema.Uno de los grandes argumentos científicos en torno a la IA generativa (y, de hecho, la IA general). Mientras tanto, independientemente de lo que pienses que serán estos modelos dentro de un par de años, hay mucho que no está ahí hoy en día. Estas capturas de pantalla son un buen ejemplo de un caso de uso que tengo, que debería funcionar y no lo hace... todavía.

El problema más profundo, creo, es que no importa cuán buena sea la tecnología, debes pensar en el caso de uso. Debes verlo. Debes notar algo que pasas mucho tiempo haciendo y darte cuenta de que podría ser automatizado con una herramienta como esta.

Parte de esto se trata de imaginación y familiaridad. Me recuerda un poco los primeros días de Google, cuando estábamos tan acostumbrados a crear soluciones personalizadas para problemas que tomó tiempo darnos cuenta de que podías "simplemente buscarlo en Google". De hecho, había incluso libros sobre cómo usar Google, al igual que hoy en día hay ensayos largos y videos sobre cómo aprender "ingeniería de prompts".

Tomó tiempo darnos cuenta de que podías convertir esto en un problema de búsqueda general y abierto, y simplemente escribir aproximadamente lo que querías en lugar de construir consultas lógicas booleanas complejas en bases de datos verticales. Esto también es, quizás, un patrón clásico para la adopción de nueva tecnología: comienzas haciendo que se ajuste a las cosas que ya haces, donde es fácil y obvio ver que este es un caso de uso, y luego, con el tiempo, cambias la forma en que trabajas para adaptarte a la nueva herramienta.

Sin embargo, la otra parte de este patrón es que no es trabajo del usuario descubrir cómo una nueva herramienta es útil. Dan Bricklin, y en principio todo software, tuvo tres pasos: tuvo que darse cuenta de que podías poner una hoja de cálculo en software, luego tuvo que diseñar y codificarla (y hacerlo correctamente), y luego tuvo que salir y decirles a los contables por qué esto era genial.

En ese caso, tuvo un ajuste de producto-mercado casi inmediato y el producto se vendió solo, pero esto es muy raro. El concepto de ajuste de producto-mercado es que normalmente tienes que iterar tu idea del producto y tu idea del caso de uso y cliente hacia cada otro, y luego necesitas ventas. La gran falacia recurrente en startups de software de productividad es que puedes vender de abajo hacia arriba sin una fuerza de ventas, porque los usuarios verán y querrán. La realidad, con un número muy pequeño de excepciones, ha sido que solo un pequeño porcentaje de tus usuarios objetivo están interesados y listos para explorar una nueva herramienta, y para el resto, necesitarás venderles.

Por lo tanto, una hipótesis hoy en día podría ser que la IA generativa podría eliminar o minimizar el trabajo de Dan Bricklin para construir el producto, pero todavía necesitas darte cuenta de que podrías hacer esto, hacer algo tangible que exprese eso, y luego salir y decirles a la gente. La gente sabe que están haciendo impuestos, pero la mayoría de las cosas que automatizamos son cosas que no vemos o no nos damos cuenta de que estamos haciendo como una tarea separada y discreta que podría ser automatizada hasta que alguien se lo señala y trata de vendernos software.

Mientras tanto, las hojas de cálculo fueron tanto un caso de uso para una PC como un sustrato general-purpose en sí mismo, al igual que el correo electrónico o SQL podrían ser, y sin embargo, todos ellos han sido desempaquetados. La típica gran empresa de hoy en día utiliza cientos de aplicaciones SaaS diferentes, todas ellas, por así decirlo, desempaquetando algo de Excel, Oracle o Outlook. Todas ellas, en su núcleo, son una idea para un problema y una idea para un flujo de trabajo para resolver ese problema, que es más fácil de entender y desplegar que decir "¡puedes hacer eso en Excel!". Más bien, instancias el problema y la solución en software - "envuelves" - y se lo vendes a un CIO. Vendes un problema. Y mientras tanto, probablemente no querrás darle ChatGPT a Dwight o Big Keith de The Office y decirles que lo usen para facturar, tampoco querrías decirles que usen Excel en lugar de SAP.

Por lo tanto, la disonancia cognitiva de la IA generativa es que OpenAI o Anthropic dicen que estamos muy cerca de la IA general, pero...Por lo tanto, la disonancia cognitiva de la IA generativa es que OpenAI o Anthropic afirman que estamos muy cerca de agentes autónomos de propósito general que podrían manejar muchas tareas complejas multi-etapa diferentes, mientras que al mismo tiempo hayUna 'Explosión de Cámbrico' de startups que utilizan APIs de OpenAI o Anthropic para construir aplicaciones dedicadas de un solo propósito que se enfocan en un problema y lo envuelven en una interfaz de usuario personalizada, herramientas y ventas empresariales, al igual que una generación anterior lo hizo con SQL.

En 1982, mi padre tenía un (1) taladro eléctrico, pero desde entonces las empresas de herramientas han convertido eso en una constelación de fabricantes de agujeros eléctricos alimentados por baterías. En algún momento, cada startup tenía SQL dentro, pero eso no era el producto, y ahora cada startup tendrá LLMs dentro.

A menudo comparo la última ola de aprendizaje automático con internos automatizados. Quieres escuchar cada llamada que entra en el centro de llamadas y reconocer qué clientes suenan enojados o sospechosos: hacer eso no necesitaba un experto, solo un humano (o incluso un perro), y ahora podrías automatizar toda esa clase de problema. Detectar esos problemas y construir ese software toma tiempo: el avance del aprendizaje automático fue hace más de una década, y todavía estamos inventando nuevos casos de uso para él - la gente sigue creando empresas basadas en darse cuenta de que X o Y es un problema, darse cuenta de que se puede convertir en reconocimiento de patrones, y luego salir y vender ese problema.

Podrías proponer la actual ola de IA generativa como darnos otro conjunto de internos, que pueden hacer cosas además de reconocerlas, y, nuevamente, necesitamos trabajar para descubrir qué. Mientras tanto, el argumento de la IA generalizada se reduce a si esto podría ser mucho, mucho más que internos, y si tuviéramos eso, entonces no sería una herramienta más.

Pero incluso si tuviera un interno humano real, podría ser muy difícil para ellos resolver la solicitud de 'un disparo' en mis capturas de pantalla de arriba. Tendrías que saber que estoy pidiendo un conjunto de datos de serie temporal, con probablemente un número por año, pero tal vez uno por década, de personas como empleados por ocupación (no, por ejemplo, personas empleadas por operadores de ascensores), a nivel nacional y no estatal, y luego irías al sitio web del Censo de los EE. UU. y descubrirías que recopila este tipo de cosas, pero en varias capas de detalle, a intervalos diferentes, con definiciones diferentes, y cambia las definiciones cada pocas décadas, y dejó de recopilar 'operadores de ascensores' en algún momento (así que no está en los datos actuales en absoluto, solo en los datos pasados), y mientras tanto, el sitio web tiene docenas y docenas de herramientas y fuentes de datos diferentes, y podría ser una profesión entera solo para saber cómo encontrar algo.

En ese punto, me dirigiría de vuelta al escritorio del interno y les diría que deberían intentar FRED, y si eso no tiene, entonces sería más rápido escribir los datos uno a uno, año a año, desde escaneos de los antiguos Abstractos Estadísticos, y que son más fáciles de buscar utilizando las copias en Google Books, que están escaneadas desde bibliotecas universitarias aleatorias.INTELIGENCIA ARTIFICIAL
, 
PRODUCTIVIDAD
19 ABRIL 2024
Anterior
IA y problemas de escala
Esta es una ilustración divertida de la vieja broma de que un programador pasará una semana automatizando una tarea que tomaría un día hacer a mano. También es un gran gráfico de automatización y me tomó horas teclear todo esto a mano, así que lo estoy utilizando.

¿Cuánto conocimiento incorporado es eso? ¿Puedes llegar allí con un modelo mejor? ¿Un agente multimodal? ¿Colaboración multiagente?

¿O es mejor capturar todo ese conocimiento incorporado con una GUI, en una aplicación o servicio dedicado de algún tipo, donde las opciones y opciones están predefinidas por alguien que entiende la recuperación de datos o impuestos o disputas de multas de estacionamiento? Una GUI le dice al usuario qué puede hacer, pero también le dice al computadora todo lo que ya sabemos sobre el problema, y con una solicitud abierta y general, el usuario tiene que pensar en todo eso mismo, cada vez, o esperar que ya esté en los datos de entrenamiento. ¿Puede la GUI en sí misma ser generativa? ¿O necesitamos otra generación completa de Dan Bricklins para ver el problema y luego convertirlo en aplicaciones, miles de ellas, una a la vez, cada una con algún LLM en el capó?

En este sentido, todavía tendríamos un cambio de varios órdenes de magnitud en cuanto a cuánto se puede automatizar y cuántos casos de uso se pueden encontrar para LLMs, pero todavía necesitan ser encontrados y construidos uno a uno. El cambio sería que estos nuevos casos de uso serían cosas que aún se automatizan una a una, pero que no podrían haber sido automatizadas antes, o que habrían necesitado mucho más software (y capital) para automatizar. Eso haría que los LLMs sean el nuevo SQL, no el nuevo HAL9000.

* Visicalc necesitó un Apple II con 32k de RAM, y con una unidad de disquete, impresora y monitor, el precio de lista de Apple en 1979 fue de $2,875 (más impuestos), que es alrededor de $12,000 en dólares de 2024.Siguiente

El problema de la ética de la IA
Boletín informativo
2024
¿Qué importó en tecnología esta semana?
Una vez a la semana, envío un boletín informativo a 175,000 personas - lo que sucedió en tecnología que realmente importó, y lo que significa.
Selecciono los cambios y las ideas que no querrás perder en todo el ruido, y les doy contexto y análisis.
SUSCRÍBETE
© BENEDICT EVANS